import streamlit as st
import pandas as pd
import requests
import json
from datetime import datetime
from io import StringIO, BytesIO
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload, MediaIoBaseDownload
from google.oauth2.credentials import Credentials

# ğŸ” 1. refresh_token ã‚’ Drive ã«ä¿å­˜ï¼ˆä¸Šæ›¸ãå¯¾å¿œï¼‰
def save_refresh_token_to_drive(refresh_token, access_token, folder_id):
    try:
        creds = Credentials(token=access_token)
        service = build("drive", "v3", credentials=creds)

        query = f"'{folder_id}' in parents and name='refresh_token.csv'"
        results = service.files().list(q=query, fields="files(id)").execute()
        files = results.get("files", [])

        csv_content = f"refresh_token\n{refresh_token}"
        media = MediaIoBaseUpload(StringIO(csv_content), mimetype="text/csv")

        if files:
            file_id = files[0]["id"]
            service.files().update(fileId=file_id, media_body=media).execute()
        else:
            file_metadata = {
                "name": "refresh_token.csv",
                "parents": [folder_id],
                "mimeType": "application/vnd.google-apps.spreadsheet"
            }
            service.files().create(body=file_metadata, media_body=media, fields="id").execute()
    except Exception as e:
        print("âŒ refresh_token ä¿å­˜å¤±æ•—:", e)

# ğŸ“¥ 2. Driveã‹ã‚‰ refresh_token.csv ã‚’èª­ã¿è¾¼ã‚€
def load_refresh_token_from_drive(access_token, folder_id):
    try:
        creds = Credentials(token=access_token)
        service = build("drive", "v3", credentials=creds)

        query = f"'{folder_id}' in parents and name='refresh_token.csv'"
        results = service.files().list(q=query, fields="files(id)").execute()
        files = results.get("files", [])

        if not files:
            return None

        file_id = files[0]["id"]
        request = service.files().get_media(fileId=file_id)
        fh = BytesIO()
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while not done:
            status, done = downloader.next_chunk()

        fh.seek(0)
        df = pd.read_csv(fh)
        return df["refresh_token"].iloc[0]
    except Exception as e:
        print("âŒ refresh_token èª­ã¿è¾¼ã¿å¤±æ•—:", e)
        return None

# ğŸ”„ 3. refresh_token ã‹ã‚‰ access_token ã‚’å†å–å¾—
def get_access_token_from_refresh_token(refresh_token, client_id, client_secret, token_uri):
    try:
        refresh_data = {
            "client_id": client_id,
            "client_secret": client_secret,
            "refresh_token": refresh_token,
            "grant_type": "refresh_token"
        }

        response = requests.post(token_uri, data=refresh_data)
        response.raise_for_status()
        token_json = response.json()
        return token_json.get("access_token")
    except Exception as e:
        print("âŒ access_token å†å–å¾—å¤±æ•—:", e)
        return None

# 4. ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–æ™‚ã«access_tokenã‚’å¾©å…ƒã™ã‚‹å‡¦ç†
def restore_access_token_if_needed(client_id, client_secret, token_uri, folder_id):
    if "access_token" not in st.session_state:
        st.info("ğŸ”„ ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å…ƒä¸­...")

        # Drive ã‹ã‚‰ refresh_token ã‚’èª­ã¿è¾¼ã‚€
        refresh_token = load_refresh_token_from_drive(access_token="", folder_id=folder_id)
        if not refresh_token:
            st.warning("âš ï¸ refresh_token ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™ã€‚")
            return

        # refresh_token ã‹ã‚‰ access_token ã‚’å†å–å¾—
        access_token = get_access_token_from_refresh_token(refresh_token, client_id, client_secret, token_uri)
        if access_token:
            st.session_state.access_token = access_token
            st.success("âœ… access_token ã‚’å¾©å…ƒã—ã¾ã—ãŸ")
        else:
            st.error("âŒ access_token ã®å¾©å…ƒã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†èªè¨¼ã—ã¦ãã ã•ã„ã€‚")

# ğŸ•’ 5. æ‰“åˆ»ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
def generate_punch_record(name, mode):
    now = datetime.now()
    timestamp = now.strftime("%Y-%m-%d %H:%M:%S")
    year = now.strftime("%Y")
    filename = f"{year}_timecard.csv"

    record_df = pd.DataFrame([{
        "åå‰": name,
        "ãƒ¢ãƒ¼ãƒ‰": mode,
        "æ™‚åˆ»": timestamp
    }])

    return filename, timestamp, record_df

# ğŸ“ 6. ãƒ•ã‚©ãƒ«ãƒ€ã®å­˜åœ¨ç¢ºèªã¨è‡ªå‹•ä½œæˆ
def ensure_folder_exists(folder_name, access_token):
    creds = Credentials(token=access_token)
    service = build("drive", "v3", credentials=creds)

    query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
    results = service.files().list(q=query, fields="files(id, name, parents)").execute()
    files = results.get("files", [])



    if files:
        return files[0]["id"]
    else:
        metadata = {
            "name": folder_name,
            "mimeType": "application/vnd.google-apps.folder"
        }
        folder = service.files().create(body=metadata, fields="id").execute()
        st.write("ğŸ“ æ–°è¦ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸ:", folder)
        return folder.get("id")

def upload_to_drive(access_token, filename, new_csv_data, folder_id=None):
    try:
        st.write("ğŸ“ upload_to_drive ã«æ¸¡ã•ã‚ŒãŸ folder_id:", folder_id)
        creds = Credentials(token=access_token)
        service = build("drive", "v3", credentials=creds)

        query = f"name='{filename}'"
        if folder_id:
            query += f" and '{folder_id}' in parents"

        results = service.files().list(q=query, fields="files(id)").execute()
        files = results.get("files", [])

        if files:
            file_id = files[0]["id"]

            # ğŸ” æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®è¦ªãƒ•ã‚©ãƒ«ãƒ€ç¢ºèª
            file_metadata = service.files().get(fileId=file_id, fields="id, name, parents").execute()
            current_parents = file_metadata.get("parents", [])

            # ğŸ”½ æ—¢å­˜CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            request = service.files().get_media(fileId=file_id)
            fh = BytesIO()
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()
            fh.seek(0)

            # ğŸ”„ CSVã‚’çµåˆ
            existing_df = pd.read_csv(fh)
            new_df = pd.read_csv(BytesIO(new_csv_data))
            combined_df = pd.concat([existing_df, new_df], ignore_index=True)
            updated_csv = combined_df.to_csv(index=False).encode("utf-8")
            media = MediaIoBaseUpload(BytesIO(updated_csv), mimetype="text/csv")

            # ğŸ›  ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹æ›´æ–°ï¼‹ãƒ•ã‚©ãƒ«ãƒ€ç§»å‹•ï¼ˆå¿…è¦ãªã‚‰ï¼‰
            update_response = service.files().update(
                fileId=file_id,
                media_body=media,
                addParents=folder_id if folder_id else None,
                removeParents=",".join(current_parents) if folder_id else None
            ).execute()

            st.write("âœ… ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†:", update_response)
            st.write("ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ç§»å‹•: æ—§ â†’", current_parents, "â†’ æ–° â†’", folder_id)
            return True, filename

        else:
            # ğŸ†• æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            media = MediaIoBaseUpload(BytesIO(new_csv_data), mimetype="text/csv")
            metadata = {
                "name": filename,
                "mimeType": "text/csv"
            }
            if folder_id:
                metadata["parents"] = [folder_id]

            response = service.files().create(
                body=metadata,
                media_body=media,
                fields="id, name, parents, webViewLink"
            ).execute()

            st.write("ğŸ“„ ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:", response)
            st.write("ğŸ“ ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ID:", response.get("parents"))
            st.write("ğŸ”— ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯:", response.get("webViewLink"))
            return True, filename

    except Exception as e:
        st.error("âŒ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—")
        st.write("ã‚¨ãƒ©ãƒ¼å†…å®¹:", str(e))
        return False

# ğŸ§© 8. æ‰“åˆ»å‡¦ç†ã®çµ±åˆé–¢æ•°ï¼ˆãƒ•ã‚©ãƒ«ãƒ€è‡ªå‹•ä½œæˆä»˜ãï¼‰
def record_punch(name, mode, access_token, folder_name=None):
    folder_id = None
    if folder_name:
        folder_id = ensure_folder_exists(folder_name, access_token)

    filename, timestamp, df = generate_punch_record(name, mode)
    csv_data = df.to_csv(index=False).encode("utf-8")
    success, filename = upload_to_drive(access_token, filename, csv_data, folder_id)
    return timestamp, success, filename  

# ğŸ§© ex. ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèª
def check_file_exists(filename, access_token, folder_id=None):
    creds = Credentials(token=access_token)
    service = build("drive", "v3", credentials=creds)

    # ğŸ” ã‚¯ã‚¨ãƒªæ§‹ç¯‰ï¼ˆfolder_id ã®æœ‰ç„¡ã§åˆ†å²ï¼‰
    if folder_id:
        query = f"name='{filename}' and mimeType='text/csv' and '{folder_id}' in parents"
    else:
        query = f"name='{filename}' and mimeType='text/csv'"

    st.write("ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª:", query)  # â† ãƒ‡ãƒãƒƒã‚°ç”¨ã«è¡¨ç¤º

    results = service.files().list(q=query, fields="files(id, name, parents)").execute()
    files = results.get("files", [])

    if files:
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã¯ Drive ã«å­˜åœ¨ã—ã¾ã™")
        st.write("ğŸ“ æ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:", files)
        return True
    else:
        st.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã¯ Drive ã«å­˜åœ¨ã—ã¾ã›ã‚“")
        return False
