import streamlit as st
import pandas as pd
import requests
import json
from datetime import datetime
from io import StringIO, BytesIO
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload, MediaIoBaseDownload
from google.oauth2.credentials import Credentials

# ğŸ” 1. refresh_token ã‚’ Drive ã«ä¿å­˜ï¼ˆä¸Šæ›¸ãå¯¾å¿œï¼‰
def save_refresh_token_to_drive(refresh_token, access_token, folder_id):
    try:
        creds = Credentials(token=access_token)
        service = build("drive", "v3", credentials=creds)

        query = f"'{folder_id}' in parents and name='refresh_token.csv'"
        results = service.files().list(q=query, fields="files(id)").execute()
        files = results.get("files", [])

        csv_content = f"refresh_token\n{refresh_token}"
        media = MediaIoBaseUpload(StringIO(csv_content), mimetype="text/csv")

        if files:
            file_id = files[0]["id"]
            service.files().update(fileId=file_id, media_body=media).execute()
        else:
            file_metadata = {
                "name": "refresh_token.csv",
                "parents": [folder_id],
                "mimeType": "application/vnd.google-apps.spreadsheet"
            }
            service.files().create(body=file_metadata, media_body=media, fields="id").execute()
    except Exception as e:
        print("âŒ refresh_token ä¿å­˜å¤±æ•—:", e)

# ğŸ“¥ 2. Driveã‹ã‚‰ refresh_token.csv ã‚’èª­ã¿è¾¼ã‚€
def load_refresh_token_from_drive(access_token, folder_id):
    try:
        creds = Credentials(token=access_token)
        service = build("drive", "v3", credentials=creds)

        query = f"'{folder_id}' in parents and name='refresh_token.csv'"
        results = service.files().list(q=query, fields="files(id)").execute()
        files = results.get("files", [])

        if not files:
            return None

        file_id = files[0]["id"]
        request = service.files().get_media(fileId=file_id)
        fh = BytesIO()
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while not done:
            status, done = downloader.next_chunk()

        fh.seek(0)
        df = pd.read_csv(fh)
        return df["refresh_token"].iloc[0]
    except Exception as e:
        print("âŒ refresh_token èª­ã¿è¾¼ã¿å¤±æ•—:", e)
        return None

# ğŸ”„ 3. refresh_token ã‹ã‚‰ access_token ã‚’å†å–å¾—
def get_access_token_from_refresh_token(refresh_token, client_id, client_secret, token_uri):
    try:
        refresh_data = {
            "client_id": client_id,
            "client_secret": client_secret,
            "refresh_token": refresh_token,
            "grant_type": "refresh_token"
        }

        response = requests.post(token_uri, data=refresh_data)
        response.raise_for_status()
        token_json = response.json()
        return token_json.get("access_token")
    except Exception as e:
        print("âŒ access_token å†å–å¾—å¤±æ•—:", e)
        return None

# ğŸ•’ 4. æ‰“åˆ»ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
def generate_punch_record(name, mode):
    now = datetime.now()
    timestamp = now.strftime("%Y-%m-%d %H:%M:%S")
    year = now.strftime("%Y")
    filename = f"{year}_timecard.csv"

    record_df = pd.DataFrame([{
        "åå‰": name,
        "ãƒ¢ãƒ¼ãƒ‰": mode,
        "æ™‚åˆ»": timestamp
    }])

    return filename, timestamp, record_df

# ğŸ“ 5. ãƒ•ã‚©ãƒ«ãƒ€ã®å­˜åœ¨ç¢ºèªã¨è‡ªå‹•ä½œæˆ
def ensure_folder_exists(folder_name, access_token):
    creds = Credentials(token=access_token)
    service = build("drive", "v3", credentials=creds)

    query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder'"
    results = service.files().list(q=query, fields="files(id)").execute()
    files = results.get("files", [])

    if files:
        return files[0]["id"]
    else:
        metadata = {
            "name": folder_name,
            "mimeType": "application/vnd.google-apps.folder"
        }
        folder = service.files().create(body=metadata, fields="id").execute()
        return folder.get("id")

# ğŸ“¤ 6. Google Drive ã«CSVã‚’è¿½è¨˜ä¿å­˜
def upload_to_drive(access_token, filename, new_csv_data, folder_id=None):
    try:
        creds = Credentials(token=access_token)
        service = build("drive", "v3", credentials=creds)

        query = f"name='{filename}'"
        if folder_id:
            query += f" and '{folder_id}' in parents"

        results = service.files().list(q=query, fields="files(id)").execute()
        files = results.get("files", [])

        if files:
            file_id = files[0]["id"]
            request = service.files().get_media(fileId=file_id)
            fh = BytesIO()
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()

            fh.seek(0)
            existing_df = pd.read_csv(fh)
            new_df = pd.read_csv(BytesIO(new_csv_data))
            combined_df = pd.concat([existing_df, new_df], ignore_index=True)

            updated_csv = combined_df.to_csv(index=False).encode("utf-8")
            media = MediaIoBaseUpload(BytesIO(updated_csv), mimetype="text/csv")
            update_response = service.files().update(fileId=file_id, media_body=media).execute()
            st.write("âœ… ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†:", update_response)
            return True, filename          
            #service.files().update(fileId=file_id, media_body=media).execute()
        else:
            media = MediaIoBaseUpload(BytesIO(new_csv_data), mimetype="text/csv")
            metadata = {
                "name": filename,
                "mimeType": "text/csv"
            }
            if folder_id:
                metadata["parents"] = [folder_id]
                # ğŸ”§ webViewLink ã‚’å«ã‚ã¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                response = service.files().create(
                    body=metadata,
                    media_body=media,
                    fields="id, name, parents, webViewLink"
                ).execute()
                
                # ğŸ” ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’è¡¨ç¤º
                st.write("ğŸ“„ ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:", response)
                st.write("ğŸ”— ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯:", response.get("webViewLink"))

            #response = service.files().create(body=metadata, media_body=media, fields="id, name, parents").execute()
            #st.write("ğŸ“„ ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:", response)
                return True, filename  # â† ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿”ã™
    except Exception as e:
        st.error("âŒ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—")
        st.write(("ã‚¨ãƒ©ãƒ¼å†…å®¹:", str(e)))
        return False

# ğŸ§© 7. æ‰“åˆ»å‡¦ç†ã®çµ±åˆé–¢æ•°ï¼ˆãƒ•ã‚©ãƒ«ãƒ€è‡ªå‹•ä½œæˆä»˜ãï¼‰
def record_punch(name, mode, access_token, folder_name=None):
    folder_id = None
    if folder_name:
        folder_id = ensure_folder_exists(folder_name, access_token)

    filename, timestamp, df = generate_punch_record(name, mode)
    csv_data = df.to_csv(index=False).encode("utf-8")
    success, filename = upload_to_drive(access_token, filename, csv_data, folder_id)
    return timestamp, success, filename  

# ğŸ§© ex. ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèª
def check_file_exists(filename, access_token, folder_id=None):
    creds = Credentials(token=access_token)
    service = build("drive", "v3", credentials=creds)

    query = f"name='{filename}' and mimeType='text/csv'"
    if folder_id:
        query += f" and '{folder_id}' in parents"

    results = service.files().list(q=query, fields="files(id, name)").execute()
    files = results.get("files", [])

    if files:
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã¯ Drive ã«å­˜åœ¨ã—ã¾ã™")
        return True
    else:
        st.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã¯ Drive ã«å­˜åœ¨ã—ã¾ã›ã‚“")
        return False
